{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "TestRoadDamageDatasetTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM0Jh1llVGYF",
        "colab_type": "text"
      },
      "source": [
        "# **Assessing the Results of Road Defect Detection Model**\n",
        "Small adaptations made to original tutorial by Sekilabs (https://github.com/sekilab/RoadDamageDetector/blob/master/RoadDamageDatasetTutorial.ipynb)\n",
        "\n",
        "**Data**\n",
        "- Collected and annotated (PASCAL VOC format) by Maeda et al. \n",
        "- Comprised of 9,053 road damage images captured with a smartphone installed on a car, with 15,435 instances of road surface damage included in these road images\n",
        "- RoadCrackDataset across 7 municipalities in Japan\n",
        "    - Adachi\n",
        "        - JPEGImages : contains images\n",
        "        - Annotations : contains xml files of annotation\n",
        "        - ImageSets : contains text files that show training or evaluation \n",
        "    - Chiba\n",
        "    - Muroran\n",
        "    - Ichihara\n",
        "    - Sumida\n",
        "    - Nagakute\n",
        "    - Numazu\n",
        "\n",
        "Maeda, H., Sekimoto, Y., Seto, T., Kashiyama, T., & Omata, H. Road Damage Detection and Classification Using Deep Neural Networks with Smartphone Images. Computer‐Aided Civil and Infrastructure Engineering. \n",
        "[Read Paper](https://arxiv.org/pdf/1801.09454.pdf)\n",
        "\n",
        "**Model**\n",
        "\n",
        "Links to the frozen model provided by the Maeda et al. were found to be broken. Hence a new model was trained on SSD MobileNet (see see Training a Road Defect Detector_v0.1.ipynb)\n",
        "\n",
        "- Uploaded trained models and label map file to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMfQmWAHVGYL",
        "colab_type": "text"
      },
      "source": [
        "**Read Data**\n",
        "\n",
        "Data was uploaded to google drive, and notebook evaluation was run on google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeSH_xBUlqtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "edcd754c-1c06-458e-cec3-ae768664df53"
      },
      "source": [
        "# mount to drive\n",
        "# will be prompted for authorisation code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-aElJntVGYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import six.moves.urllib as urllib\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_KRxDPrk5N-",
        "colab_type": "code",
        "outputId": "4c156ab4-9e4d-4d5a-9df7-759b5c7c7eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# downloaded dataset and uploaded to google drive\n",
        "# need to mount drive\n",
        "cd /content/drive/My Drive/RoadDamageDataset/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/RoadDamageDataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJPsOEkdVGYT",
        "colab_type": "code",
        "outputId": "5f2b8091-fdbc-4212-9849-88bc4a35b68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "\n",
        "if not os.path.exists('./RoadDamageDataset.tar.gz'):\n",
        "  # this url doesn't work\n",
        "    url_base = 'https://s3-ap-northeast-1.amazonaws.com/mycityreport/RoadDamageDataset.tar.gz'\n",
        "    urllib.request.urlretrieve(url_base, './RoadDamageDataset.tar.gz')\n",
        "    \n",
        "    print(\"Download RoadDamageDataset.tar.gz Done\")\n",
        "    \n",
        "else:\n",
        "    print(\"You have RoadDamageDataset.tar.gz\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have RoadDamageDataset.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqiarJcbmmGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e33c257-e252-4aba-d7fe-05ec1af8f7c4"
      },
      "source": [
        "# this procces may take a few minutes\n",
        "!tar -zxf ./RoadDamageDataset.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: RoadDamageDataset/Numazu/JPEGImages/._Numazu_20170906133631.jpg: Cannot open: Input/output error\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwM-nwqJVGYg",
        "colab_type": "text"
      },
      "source": [
        "**Data Exploration**\n",
        "\n",
        "Understanding the distribution of each type of road defects across mulicipalities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj1WdyuHVGYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63797291-d992-41de-acf4-5f1c85d628a6"
      },
      "source": [
        "from xml.etree import ElementTree\n",
        "from xml.dom import minidom\n",
        "import collections\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as matplot\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW_xxP_jVGYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = os.getcwd() + '/RoadDamageDataset/'\n",
        "\n",
        "damageTypes=[\"D00\", \"D01\", \"D10\", \"D11\", \"D20\", \"D40\", \"D43\", \"D44\"]\n",
        "\n",
        "# govs corresponds to municipality name.\n",
        "govs = [\"Adachi\", \"Chiba\", \"Ichihara\", \"Muroran\", \"Nagakute\", \"Numazu\", \"Sumida\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79KZbdxQVGYo",
        "colab_type": "code",
        "outputId": "141be635-638c-476c-901a-38d1d8416939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# the number of total images and total labels.\n",
        "cls_names = []\n",
        "total_images = 0\n",
        "for gov in govs:\n",
        "    \n",
        "    file_list = [filename for filename in os.listdir(base_path + gov + '/Annotations/') if not filename.startswith('.')]\n",
        "\n",
        "    for file in file_list:\n",
        "\n",
        "        total_images = total_images + 1\n",
        "        if file =='.DS_Store':\n",
        "            pass\n",
        "        else:\n",
        "            infile_xml = open(base_path + gov + '/Annotations/' +file)\n",
        "            tree = ElementTree.parse(infile_xml)\n",
        "            root = tree.getroot()\n",
        "            for obj in root.iter('object'):\n",
        "                cls_name = obj.find('name').text\n",
        "                cls_names.append(cls_name)\n",
        "print(\"total\")\n",
        "print(\"# of images：\" + str(total_images))\n",
        "print(\"# of labels：\" + str(len(cls_names)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total\n",
            "# of images：9053\n",
            "# of labels：15457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "j-Gc4gqdVGYs",
        "colab_type": "code",
        "outputId": "acfb83d0-b568-4faf-b05b-77c3593e0d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# the number of each class labels.\n",
        "import collections\n",
        "count_dict = collections.Counter(cls_names)\n",
        "cls_count = []\n",
        "for damageType in damageTypes:\n",
        "    print(str(damageType) + ' : ' + str(count_dict[damageType]))\n",
        "    cls_count.append(count_dict[damageType])\n",
        "    \n",
        "sns.set_palette(\"winter\", 8)\n",
        "sns.barplot(damageTypes, cls_count)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D00 : 2768\n",
            "D01 : 3789\n",
            "D10 : 742\n",
            "D11 : 636\n",
            "D20 : 2541\n",
            "D40 : 409\n",
            "D43 : 817\n",
            "D44 : 3733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4314288e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvsnO80oVGYv",
        "colab_type": "code",
        "outputId": "be719504-7bb6-4fac-f873-843cb7dfdc8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# the number of each class labels for each municipality\n",
        "for gov in govs:\n",
        "    cls_names = []\n",
        "    total_images = 0\n",
        "    file_list = [filename for filename in os.listdir(base_path + gov + '/Annotations/') if not filename.startswith('.')]\n",
        "\n",
        "    for file in file_list:\n",
        "\n",
        "        total_images = total_images + 1\n",
        "        if file =='.DS_Store':\n",
        "            pass\n",
        "        else:\n",
        "            infile_xml = open(base_path + gov + '/Annotations/' +file)\n",
        "            tree = ElementTree.parse(infile_xml)\n",
        "            root = tree.getroot()\n",
        "            for obj in root.iter('object'):\n",
        "                cls_name = obj.find('name').text\n",
        "                cls_names.append(cls_name)\n",
        "    print(gov)\n",
        "    print(\"# of images：\" + str(total_images))\n",
        "    print(\"# of labels：\" + str(len(cls_names)))\n",
        "    \n",
        "    count_dict = collections.Counter(cls_names)\n",
        "    cls_count = []\n",
        "    for damageType in damageTypes:\n",
        "        print(str(damageType) + ' : ' + str(count_dict[damageType]))\n",
        "        cls_count.append(count_dict[damageType])\n",
        "        \n",
        "    print('**************************************************')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adachi\n",
            "# of images：1650\n",
            "# of labels：2924\n",
            "D00 : 529\n",
            "D01 : 1013\n",
            "D10 : 153\n",
            "D11 : 279\n",
            "D20 : 172\n",
            "D40 : 11\n",
            "D43 : 191\n",
            "D44 : 567\n",
            "**************************************************\n",
            "Chiba\n",
            "# of images：467\n",
            "# of labels：797\n",
            "D00 : 183\n",
            "D01 : 187\n",
            "D10 : 13\n",
            "D11 : 12\n",
            "D20 : 27\n",
            "D40 : 3\n",
            "D43 : 104\n",
            "D44 : 267\n",
            "**************************************************\n",
            "Ichihara\n",
            "# of images：254\n",
            "# of labels：482\n",
            "D00 : 175\n",
            "D01 : 71\n",
            "D10 : 18\n",
            "D11 : 9\n",
            "D20 : 43\n",
            "D40 : 8\n",
            "D43 : 20\n",
            "D44 : 138\n",
            "**************************************************\n",
            "Muroran\n",
            "# of images：2145\n",
            "# of labels：3601\n",
            "D00 : 671\n",
            "D01 : 574\n",
            "D10 : 124\n",
            "D11 : 88\n",
            "D20 : 1192\n",
            "D40 : 189\n",
            "D43 : 50\n",
            "D44 : 712\n",
            "**************************************************\n",
            "Nagakute\n",
            "# of images：1366\n",
            "# of labels：2302\n",
            "D00 : 482\n",
            "D01 : 477\n",
            "D10 : 169\n",
            "D11 : 58\n",
            "D20 : 351\n",
            "D40 : 14\n",
            "D43 : 90\n",
            "D44 : 659\n",
            "**************************************************\n",
            "Numazu\n",
            "# of images：2032\n",
            "# of labels：3711\n",
            "D00 : 560\n",
            "D01 : 807\n",
            "D10 : 245\n",
            "D11 : 129\n",
            "D20 : 735\n",
            "D40 : 165\n",
            "D43 : 161\n",
            "D44 : 908\n",
            "**************************************************\n",
            "Sumida\n",
            "# of images：1139\n",
            "# of labels：1640\n",
            "D00 : 168\n",
            "D01 : 660\n",
            "D10 : 20\n",
            "D11 : 61\n",
            "D20 : 21\n",
            "D40 : 19\n",
            "D43 : 201\n",
            "D44 : 482\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmmcV983VGY5",
        "colab_type": "text"
      },
      "source": [
        "# Check some images in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC6TgwooVGY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwifMUYaVGY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_images(image_file):\n",
        "    gov = image_file.split('_')[0]\n",
        "    img = cv2.imread(base_path + gov + '/JPEGImages/' + image_file.split('.')[0] + '.jpg')\n",
        "    \n",
        "    infile_xml = open(base_path + gov + '/Annotations/' +image_file)\n",
        "    tree = ElementTree.parse(infile_xml)\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    for obj in root.iter('object'):\n",
        "        cls_name = obj.find('name').text\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        xmin = int(xmlbox.find('xmin').text)\n",
        "        xmax = int(xmlbox.find('xmax').text)\n",
        "        ymin = int(xmlbox.find('ymin').text)\n",
        "        ymax = int(xmlbox.find('ymax').text)\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        # put text\n",
        "        cv2.putText(img,cls_name,(xmin,ymin-10),font,1,(0,255,0),2,cv2.LINE_AA)\n",
        "\n",
        "        # draw bounding box\n",
        "        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0,255,0),3)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "h3CjVFFXVGY_",
        "colab_type": "code",
        "outputId": "45ab741f-2814-413f-f2fc-10b361bf9d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "for damageType in damageTypes:\n",
        "    tmp = []\n",
        "    for gov in govs:\n",
        "        file = open(base_path + gov + '/ImageSets/Main/%s_trainval.txt' %damageType, 'r')\n",
        "\n",
        "        for line in file:\n",
        "            line = line.rstrip('\\n').split('/')[-1]\n",
        "\n",
        "            if line.split(' ')[2] == '1':\n",
        "                tmp.append(line.split(' ')[0]+'.xml')\n",
        "        \n",
        "        \n",
        "    random.shuffle(tmp)\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    for number, image in enumerate(tmp[0:1]):\n",
        "        img = draw_images(image)\n",
        "        #plt.subplot(1,1,number)\n",
        "        plt.axis('off')\n",
        "        plt.title('The image including ' + damageType)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-61b475159f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The image including '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdamageType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clMMlvEeVGZE",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "Evaluating the results of the model on unseen municipalities data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3jY_AlRKVGZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "#we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow.compat.v1 as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEUmB6xAsUU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download Tensorflow\n",
        "%cd /content/drive/My Drive/RoadDamageDataset\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgHKj-Dru5XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/RoadDamageDataset/models/research\n",
        "#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
        "os.environ['PYTHONPATH'] += ':/content/road_defect_detection/models/research/:/content/road_defect_detection/models/research/slim/'\n",
        "sys.path.append('/content/drive/My Drive/object_detection/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91gXERCCVGZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LFWHEzfVGZO",
        "colab_type": "text"
      },
      "source": [
        "**Loading the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTj2ifIaVGZP",
        "colab_type": "text"
      },
      "source": [
        "## Variables\n",
        "\n",
        "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.  \n",
        "\n",
        "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QNuOgqlVGZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/RoadDamageDataset/\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT =  'trainedModels/ssd_mobilenet_RoadDamageDetector_Custom Road Defect Detector.pb' \n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'trainedModels/crack_label_map.pbtxt'\n",
        "\n",
        "NUM_CLASSES = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElbS5JJiVGZU",
        "colab_type": "text"
      },
      "source": [
        "**Load a (frozen) Tensorflow model into memory.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr2KHIkLVGZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6HTieQBVGZX",
        "colab_type": "text"
      },
      "source": [
        "**Load label map**\n",
        "\n",
        "Label maps map indices to category names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxi8FgBvVGZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbE-JMvXVGZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhz5DG6OVGZd",
        "colab_type": "text"
      },
      "source": [
        "**Road Defect Detection**\n",
        "\n",
        "- Randomly sample test set for evaluation\n",
        "- Visually inspect and validate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nAc7HW8DVGZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get images from val.txt\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/RoadDamageDataset/RoadDamageDataset/'\n",
        "D_TYPE = ['D00', 'D01', 'D10', 'D11', 'D20','D40', 'D43']\n",
        "govs = ['Adachi', 'Ichihara', 'Muroran', 'Chiba', 'Sumida', 'Nagakute', 'Numazu']\n",
        "\n",
        "val_list = []\n",
        "for gov in govs:\n",
        "    file = open(PATH_TO_TEST_IMAGES_DIR + gov + '/ImageSets/Main/val.txt', 'r')\n",
        "    for line in file:\n",
        "        line = line.rstrip('\\n').split('/')[-1]\n",
        "        val_list.append(line)\n",
        "    file.close()\n",
        "\n",
        "print(\"# of validation images：\" + str(len(val_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXIWiqKDVGZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_IMAGE_PATHS=[]\n",
        "random.shuffle(val_list)\n",
        "\n",
        "for val_image in val_list[0:5]:\n",
        "    TEST_IMAGE_PATHS.append(PATH_TO_TEST_IMAGES_DIR + val_image.split('_')[0]+ '/JPEGImages/%s.jpg' %val_image)\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GBvR_7jNVGZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    # Definite input and output Tensors for detection_graph\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    # Each box represents a part of the image where a particular object was detected.\n",
        "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    # Each score represent how level of confidence for each of the objects.\n",
        "    # Score is shown on the result image, together with the class label.\n",
        "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "    for image_path in TEST_IMAGE_PATHS:\n",
        "      image = Image.open(image_path)\n",
        "      # the array based representation of the image will be used later in order to prepare the\n",
        "      # result image with boxes and labels on it.\n",
        "      image_np = load_image_into_numpy_array(image)\n",
        "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          min_score_thresh=0.3,\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=8)\n",
        "      plt.figure(figsize=IMAGE_SIZE)\n",
        "      plt.imshow(image_np)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyzE3hPpVGZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -rf ./RoadDamageDataset.tar.gz\n",
        "#!rm -rf ./RoadDamageDataset\n",
        "#!rm -rf ./trainedModels.tar.gz\n",
        "#!rm -rf ./trainedModels"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}